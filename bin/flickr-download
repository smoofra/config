#!/usr/bin/env python3

import os
import sys
import xml.etree
import xml.etree.ElementTree
import json
import argparse
import multiprocessing
import signal
from xml.etree.ElementTree import Element
from typing import cast, Any

import flickrapi
import requests

def getchildren(self):
    return list(self)
cast(Any, Element).getchildren = getchildren

parser = argparse.ArgumentParser()
parser.add_argument("-v", "--verbose", action='store_true')
parser.add_argument("-q", "--quiet", action='store_true')
parser.add_argument("-u", "--user")
parser.add_argument("-o", "--output", required=True)
parser.add_argument("-i", "--interactive", action='store_true')
args = parser.parse_args()

if not os.path.isdir(args.output):
    parser.error("OUTPUT is not a directory")

photos_dir = os.path.join(args.output, "Photos")
if not os.path.isdir(photos_dir):
    os.mkdir(photos_dir)

infos_dir = os.path.join(args.output, "Infos")
if not os.path.isdir(infos_dir):
    os.mkdir(infos_dir)

albums_dir = os.path.join(args.output, "Albums")
if not os.path.isdir(albums_dir):
    os.mkdir(albums_dir)

with open(os.path.join(os.getenv("HOME"), ".flickr_key")) as f:
    keydict = json.load(f)

flickr = flickrapi.FlickrAPI(keydict['key'], keydict['secret'])
#flickr.authenticate_via_browser(perms='write')

if not flickr.token_valid(perms='read'):
    if not args.interactive:
        raise Exception("run again with --interactive")

    flickr.get_request_token(oauth_callback='oob')

    authorize_url = flickr.auth_url(perms='read')
    print("open url:", authorize_url)

    verifier = str(input('Verifier code: '))
    flickr.get_access_token(verifier)


if not args.quiet:
    print("authorized.")

def download(url, filename):
    tempfile = filename + '.part'
    print("%s --> %s starting" % (url, filename))
    try:
        response = requests.get(url, stream=True)
        response.raise_for_status()
        size = 0
        try:
            with open(tempfile, 'wb') as f:
                for block in response.iter_content(500 * 1024):
                    size += len(block)
                    #print "%s --> %s %dk" % (url, filename, size / 1024)
                    f.write(block)
            os.rename(tempfile, filename)
        finally:
            if os.path.exists(tempfile):
                os.unlink(tempfile)
        print("%s --> %s done" % (url, filename))
        return True
    except Exception as e:
        print("%s --> %s failed: %s" % (url, filename, e))
        raise


original_sigint_handler = signal.signal(signal.SIGINT, signal.SIG_IGN)
multiprocessing.set_start_method('fork')
pool = multiprocessing.Pool(10)
signal.signal(signal.SIGINT, original_sigint_handler)

if args.user:
    resp = flickr.people_findByUsername(username=args.user)
    userid = resp.find('user').attrib['id']
else:
    userid = 'me'


try:

    resp = flickr.photosets_getList(user_id=userid)
    for album in resp.find('photosets').findall('photoset'):
        albumid = album.attrib['id']
        album_path = os.path.join(albums_dir, albumid + ".xml")
        album_path_temp = os.path.join(albums_dir, albumid + ".xml.part")

        date = int(album.attrib['date_update'])

        if os.path.exists(album_path):
            with open(album_path, 'r') as f:
                root  = xml.etree.ElementTree.fromstring('<root>' + f.read() + '</root>')
                orig_date = int(root.find("rsp/photoset").attrib["date_update"])
        else:
            orig_date = None

        if os.path.exists(album_path) and orig_date and date <= orig_date:
            if args.verbose:
                print("album is up to date:", albumid)
            continue

        if not args.quiet:
            print("getting album info for", albumid)

        info = flickr.photosets_getInfo(user_id=userid, photoset_id=albumid)
        with open(album_path_temp, 'wb') as f:
            f.write( xml.etree.ElementTree.tostring(info, encoding='utf-8').strip())
            f.write(b'\n')
            for photo in flickr.walk_set(user_id=userid, photoset_id=albumid):
                f.write(xml.etree.ElementTree.tostring(photo, encoding='utf-8').strip())
                f.write(b'\n')
            f.write(b'\n')

        os.rename(album_path_temp, album_path)

    for photo in flickr.walk_user(extras='last_update', user_id=userid):

        photo_id = photo.attrib['id']
        photo_lastupdate = int(photo.attrib["lastupdate"])
        path = os.path.join(photos_dir, photo_id + ".jpg")
        info_path = os.path.join(infos_dir, photo_id + ".xml")

        if os.path.exists(info_path):
            with open(info_path, 'r') as f:
                orig_info  = xml.etree.ElementTree.parse(f)
                orig_date = int(orig_info.find("photo/dates").attrib["lastupdate"])
        else:
            orig_date = None

        if os.path.exists(path) and orig_date and photo_lastupdate <= orig_date:
            if args.verbose:
                print("photo is up to date:", photo_id)
            continue

        if not args.quiet:
            print("getting info for", photo_id)

        info = flickr.photos_getInfo(photo_id=photo_id)

        with open(info_path, 'wb') as f:
            f.write(xml.etree.ElementTree.tostring(info, encoding='utf-8'))

        if os.path.exists(path):
            continue

        sizes = flickr.photos_getSizes(photo_id=photo_id)
        origurl = sizes.find("sizes/size[@label='Original']").attrib["source"]

        #print "!!", photo_id, origurl, path
        pool.apply_async(download, args=(origurl, path))

except KeyboardInterrupt:
    pool.terminate()
    print("\ninterrupted.")
    sys.exit(1)
else:
    pool.close()

pool.join()
if not args.quiet:
    print("done.")
